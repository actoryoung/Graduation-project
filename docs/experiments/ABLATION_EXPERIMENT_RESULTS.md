# 消融实验结果报告

**实验日期**: 2026-02-05
**数据集**: CMU-MOSEI SDK标准子集 (processed_cleaned_correct)
**基线模型**: GloVe + COVAREP + OpenFace (手工特征)

---

## 实验目的

通过消融实验验证以下改进策略的有效性：
1. **S1**: 简化为3类问题（负/中/正）
2. **S2**: 使用Focal Loss处理类别不平衡

---

## 实验设计

### 完整消融矩阵

| 实验 | 类别数 | 损失函数 | 模型文件 |
|------|-------|---------|---------|
| 实验1（基线） | 7类 | CrossEntropy | baseline_7class_ce_best_model.pth |
| 实验2（S2单独） | 7类 | Focal Loss | baseline_7class_focal_best_model.pth |
| 实验3（S1单独） | 3类 | CrossEntropy | baseline_3class_ce_best_model.pth |
| 实验4（S1+S2） | 3类 | Focal Loss | baseline_3class_focal_best_model.pth |

### 数据分布

**7类数据分布**（processed_cleaned_correct）:
- Strong Negative (-3): 0.3%
- Negative (-2): 2.0%
- Weak Negative (-1): 7.7%
- **Neutral (0): 50.4%**
- Weak Positive (1): 28.5%
- Positive (2): 9.9%
- Strong Positive (3): 1.2%

**3类数据分布**（processed_cleaned_3class）:
- **Negative (0): 10.0%**
- **Neutral (1): 50.4%**
- **Positive (2): 39.6%**

---

## 实验结果

### 性能对比表

| 实验 | 配置 | 验证准确率 | 测试准确率 | 相对基线 | 训练时间 |
|------|------|-----------|-----------|---------|---------|
| 实验1 | 7类 + CE | 60.33% | 53.11% | - | ~10分钟 |
| 实验2 | 7类 + Focal | 60.33% | 51.48% | -1.63% ⬇️ | ~10分钟 |
| 实验3 | 3类 + CE | 65.00% | 57.54% | +4.43% ⬆️ | ~10分钟 |
| 实验4 | 3类 + Focal | 64.67% | 55.77% | +2.66% ⬆️ | ~10分钟 |

### 关键指标分析

#### 验证集性能

```
基线 (7类+CE):     60.33% ████
+Focal Loss:       60.33% ████ (无变化)
简化3类:           65.00% █████
+Focal Loss:       64.67% █████ (略微降低)
```

#### 测试集性能

```
基线 (7类+CE):     53.11% ████
+Focal Loss:       51.48% ████ (降低)
简化3类:           57.54% ██████
+Focal Loss:       55.77% █████ (降低)
```

---

## 关键发现

### 发现1: 简化为3类是最有效的改进 ✅

**数据支持**:
- 验证集提升: 60.33% → 65.00% (+4.67%)
- 测试集提升: 53.11% → 57.54% (+4.43%)

**原因分析**:
1. 减少了类别间混淆（7个细粒度类别 → 3个粗粒度类别）
2. 任务更清晰，符合实际应用场景
3. 样本分布相对更均衡（10% / 50% / 40%）

**论文价值**:
> "在严重类别不平衡（50.4%中性）的数据上，将7类情感简化为3类（负/中/正）
> 带来了最显著的性能提升（+4.43%）。这一发现表明，在细粒度分类困难的情况下，
> 粗粒度分类可能是更实用的选择。"

---

### 发现2: Focal Loss效果不佳 ❌

**数据支持**:
- 7类问题: 51.48% vs 53.11% (-1.63%)
- 3类问题: 55.77% vs 57.54% (-1.77%)

**可能原因**:
1. **参数设置不当**: gamma=2可能过于激进
2. **数据特性**: 在已经严重不平衡的数据上，Focal Loss的调节作用有限
3. **任务难度**: Focal Loss让模型过于关注难样本，但这些难样本可能本身就是噪声

**进一步验证**（可选）:
- 尝试不同的gamma值（1.5, 2.5）
- 尝试不同的alpha值（类别权重）
- 使用类别加权CrossEntropy代替Focal Loss

**论文价值**:
> "实验发现，Focal Loss在本研究的数据集上未能带来预期提升，反而略微降低
> 了性能。这表明Focal Loss并非在所有不平衡数据集上都有效，需要根据具体
> 数据特性进行调整。"

---

### 发现3: 任务简化 > 损失函数改进

**数据对比**:
| 方法 | 测试准确率 | 提升 |
|------|-----------|------|
| 基线 | 53.11% | - |
| +Focal Loss | 51.48% | -1.63% |
| +3类简化 | 57.54% | +4.43% |

**结论**:
- 任务简化带来的提升（+4.43%）远大于损失函数改进（-1.63%）
- 在类别严重不平衡的情况下，简化任务比优化损失函数更有效

---

## 最优模型配置

### 推荐: 3类 + CrossEntropy

**配置**:
```python
model = BaselineFusionModel(
    text_dim=300,
    audio_dim=74,
    video_dim=710,
    num_classes=3,  # 3类问题
    dropout_rate=0.3
)

criterion = nn.CrossEntropyLoss()  # 使用标准CE
optimizer = optim.Adam(model.parameters(), lr=1e-3)
```

**性能**:
- 验证准确率: 65.00%
- 测试准确率: 57.54%
- 相比基线提升: +4.43%

**模型文件**: `checkpoints/baseline_3class_ce_best_model.pth`

---

## 论文撰写建议

### 消融实验表格

**表X: 不同配置下的模型性能对比**

| 配置 | 类别数 | 损失函数 | Val Acc (%) | Test Acc (%) | Δ vs 基线 (%) |
|------|-------|---------|-------------|--------------|---------------|
| 基线 | 7 | CE | 60.33 | 53.11 | - |
| +Focal Loss | 7 | FL | 60.33 | 51.48 | -1.63 |
| **+3类简化** | 3 | CE | 65.00 | **57.54** | **+4.43** |
| +3类+Focal | 3 | FL | 64.67 | 55.77 | +2.66 |

### 核心论点

1. **任务简化是关键**:
   "在严重类别不平衡的数据上，简化任务（7类→3类）比优化损失函数更有效。"

2. **Focal Loss的局限性**:
   "Focal Loss在本研究的数据集上未能带来提升，说明需要根据数据特性选择合适的损失函数。"

3. **实用建议**:
   "在实际应用中，3类粗粒度分类可能是更实用的选择，既保证了性能，又符合真实场景。"

### 可视化建议

1. **性能对比柱状图**:
   - X轴: 4种配置
   - Y轴: 测试准确率
   - 标注相对基线的提升/降低

2. **混淆矩阵热力图**:
   - 7类基线 vs 3类最优
   - 展示类别简化如何改善混淆

---

## 后续实验建议

### 不推荐的方向

❌ **Focal Loss调参**:
- 效果不佳，时间成本高
- 对论文贡献有限

❌ **类别加权CrossEntropy**:
- 与Focal Loss类似，可能效果有限

### 推荐的方向

✅ **跨模态注意力机制** (S3):
- 预期提升: +2-4%
- 时间成本: 3-4小时
- 论文价值: 高

✅ **Transformer融合层** (S5):
- 预期提升: +2-4%
- 时间成本: 4-5小时
- 论文价值: 高

✅ **集成学习** (S7):
- 预期提升: +2-4%
- 时间成本: 2-3小时
- 论文价值: 中

---

## 实验文件

### 数据文件
- `data/mosei/processed_cleaned_correct/` - 7类数据
- `data/mosei/processed_cleaned_3class/` - 3类数据

### 模型文件
- `checkpoints/baseline_7class_ce_best_model.pth`
- `checkpoints/baseline_7class_focal_best_model.pth`
- `checkpoints/baseline_3class_ce_best_model.pth` ⭐ 最优
- `checkpoints/baseline_3class_focal_best_model.pth`

### 训练日志
- 每个实验的训练输出保存在对应的tool-results文件中

---

## 总结

1. ✅ **消融实验完成**: 4个实验全部完成
2. ✅ **最优配置确定**: 3类 + CrossEntropy (57.54%)
3. ✅ **关键发现**: 任务简化 > 损失函数改进
4. ⏳ **下一步**: 实施S3、S5、S7等架构改进

---

**报告生成时间**: 2026-02-05
**实验者**: Claude Code
**状态**: ✅ 消融实验完成
