# 第三章 系统设计

## 3.1 系统总体架构

### 3.1.1 系统功能需求分析

多模态情感分析系统的核心目标是整合文本、音频、视频三种模态的信息，自动识别用户表达的情感倾向（积极、中性、消极）。为实现这一目标，系统需要满足以下功能需求：

**（1）多模态数据输入**

系统应支持多种输入方式，适应不同使用场景：
- **文本直接输入**：用户提供文本内容，系统进行情感分析。这是最基础的输入方式，适用于分析评论、帖子等文本内容。
- **文件上传**：用户上传音频文件（.wav, .mp3等）或视频文件（.mp4, .avi等），系统提取特征后分析。这适用于分析现有媒体文件。
- **实时输入**：用户通过麦克风或摄像头实时输入，系统实时分析情感。这是高级功能，需要实时特征提取和推理能力。

考虑到实现难度和使用频率，本研究优先实现文本直接输入功能，对于音频和视频输入，系统设计上支持文件上传，但依赖预提取特征。

**（2）特征提取与加载**

系统需要从原始数据中提取有效的特征表示：
- **文本特征提取**：将文本转换为固定维度的向量表示。本研究使用预训练的GloVe词向量，对输入文本进行分词、词向量查找和平均池化，得到300维句子级表示。
- **音频特征提取**：提取音频信号中的声学特征。COVAREP工具能够提取74维特征，包括音高、共振峰、MFCC等。由于COVAREP的配置较为复杂，系统使用SDK提供的预提取特征。
- **视频特征提取**：提取视频中的面部表情特征。OpenFace工具能够提取710维特征，包括动作单元、头部姿态、面部landmarks等。同样，系统使用预提取特征以简化部署。

**（3）多模态融合与情感预测**

系统需要整合三种模态的特征并进行情感分类：
- **特征投影**：将异构特征（300维、74维、710维）投影到统一空间（64维），解决模态异构性问题。
- **模态融合**：使用多头注意力机制学习模态间的动态交互关系，捕捉互补信息，抑制冗余信息。
- **情感分类**：基于融合特征预测情感类别，输出三类别的概率分布和最终预测结果。

**（4）结果展示与可视化**

系统需要以直观的方式展示分析结果：
- **文本信息**：显示预测的情感类别（Negative/Neutral/Positive）和置信度分数。
- **可视化信息**：生成概率分布柱状图，直观展示三类的预测概率。
- **系统信息**：显示模型名称、版本号、响应时间等元数据。

**（5）系统交互与用户体验**

系统需要提供友好的用户界面和流畅的交互体验：
- **简洁的界面布局**：清晰的输入区域和结果展示区域，避免信息过载。
- **实时的反馈**：显示加载状态，告知用户系统正在处理。
- **错误处理**：对异常输入（如空文本、不支持的文件格式）给出明确的错误提示。

### 3.1.2 总体架构设计

基于上述需求分析，系统采用分层模块化架构，从下到上分为四层：数据输入层、特征提取层、融合推理层和结果展示层，如**图6**所示。这种分层设计保证了模块间的低耦合和高内聚，便于开发和维护。

```
┌─────────────────────────────────────────────────────────────┐
│                      结果展示层 (Presentation Layer)          │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐     │
│  │ 情感类别展示  │  │ 置信度显示    │  │ 概率分布图    │     │
│  └──────────────┘  └──────────────┘  └──────────────┘     │
└─────────────────────────────────────────────────────────────┘
                              ↑
┌─────────────────────────────────────────────────────────────┐
│                      融�推理层 (Inference Layer)              │
│  ┌──────────────────────────────────────────────────────┐  │
│  │              集成预测模块 (S7-v1)                     │  │
│  │  ┌────────────┐         ┌────────────┐              │  │
│  │  │ S3+S4模型  │   +     │  S3模型    │              │  │
│  │  │ (权重1.5)   │         │  (权重1.0)  │              │  │
│  │  └─────┬──────┘         └─────┬──────┘              │  │
│  │        │                     │                      │  │
│  │        └──────────┬──────────┘                      │  │
│  │                   ↓                                 │  │
│  │           加权软投票 (Weighted Voting)              │  │
│  │                   ↓                                 │  │
│  │         情感类别 + 概率分布 (3类)                    │  │
│  └──────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────┘
                              ↑
┌─────────────────────────────────────────────────────────────┐
│                    特征提取层 (Feature Layer)                 │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐     │
│  │ 文本特征提取  │  │ 音频特征提取  │  │ 视频特征提取  │     │
│  │ GloVe (300维)│  │ COVAREP (74维)│  │ OpenFace (710)│   │
│  └──────┬───────┘  └──────┬───────┘  └──────┬───────┘     │
│         │                  │                  │             │
│         └──────────────────┼──────────────────┘             │
│                            ↓                                │
│              ┌─────────────────────────────┐               │
│              │   模态编码器 (MLP)          │               │
│              │   300→64, 74→64, 710→64    │               │
│              └─────────────────────────────┘               │
└─────────────────────────────────────────────────────────────┘
                              ↑
┌─────────────────────────────────────────────────────────────┐
│                    数据输入层 (Input Layer)                   │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐     │
│  │ 文本输入框    │  │ 音频上传     │  │ 视频上传     │     │
│  │ (Text Input) │  │ (Audio Upload)│  │ (Video Upload)│   │
│  └──────────────┘  └──────────────┘  └──────────────┘     │
└─────────────────────────────────────────────────────────────┘
```

**架构说明**：

1. **数据输入层**：负责接收用户输入并进行预处理。文本输入框接收用户输入的文本，进行分词和清洗；音频/视频上传接收用户上传的文件，验证文件格式和大小。

2. **特征提取层**：将预处理后的数据转换为特征向量。文本特征使用GloVe词向量，音频特征使用COVAREP，视频特征使用OpenFace。为解决模态异构性，每个模态通过各自的MLP编码器投影到64维统一空间。

3. **融合推理层**：这是系统的核心层，实现多模态融合和情感预测。该层包含两个基模型（S3+S4和S3），通过加权软投票集成，最终输出三类的概率分布。

4. **结果展示层**：将预测结果渲染为用户可见的界面元素。包括情感类别标签、置信度分数和概率分布柱状图。

### 3.1.3 模块划分

基于总体架构，系统划分为五个核心模块：

| 模块名称 | 功能描述 | 输入 | 输出 |
|---------|---------|------|------|
| **数据输入模块** | 接收用户输入，验证格式，预处理 | 用户输入（文本/文件） | 清洗后的数据 |
| **特征提取模块** | 提取多模态特征，归一化 | 清洗后的数据 | 特征向量 |
| **注意力融合模块** | 实现跨模态注意力，特征融合 | 特征向量 | 融合特征 |
| **集成预测模块** | 组合基模型预测，加权投票 | 融合特征 | 情感类别+概率 |
| **结果展示模块** | 生成可视化界面 | 预测结果 | Web界面 |

**模块间的交互流程**：

```
用户输入文本
    ↓
数据输入模块 (验证非空，分词)
    ↓
特征提取模块 (GloVe查找，平均池化，L2归一化)
    ↓
注意力融合模块 (MLP编码，多头注意力，聚合)
    ↓
集成预测模块 (两个基模型推理，加权投票)
    ↓
结果展示模块 (生成类别标签，置信度，概率图)
```

---

## 3.2 数据流设计

### 3.2.1 输入模块设计

输入模块是系统与用户交互的第一道界面，其设计直接影响用户体验。该模块需要处理不同类型的输入，并进行必要的验证和预处理。

**文本输入处理流程**：

1. **输入接收**：用户在文本输入框中输入文本内容。系统设置字符数限制（建议500字符以内），避免过长文本影响响应速度。

2. **输入验证**：检查输入是否为空或仅包含空白字符。如果验证失败，显示错误提示："请输入有效的文本内容"。

3. **文本清洗**：执行以下预处理步骤：
   - 去除多余空白：将连续的空格、制表符、换行符替换为单个空格。
   - 去除特殊字符：保留中文、英文、数字和基本标点，去除其他Unicode字符。
   - 大写转小写（英文）：将英文字母统一转换为小写，与GloVe词向量保持一致。

4. **分词**：使用NLTK的word_tokenize函数进行分词，将文本切分为单词序列。例如，"I love this movie" → ["I", "love", "this", "movie"]。

**音频/视频上传处理流程**：

1. **文件接收**：用户通过文件上传组件选择音频或视频文件。

2. **文件验证**：
   - 格式验证：仅接受.wav/.mp3（音频）和.mp4/.avi（视频）格式。
   - 大小验证：限制文件大小在100MB以内，避免上传超大文件。
   - 如果验证失败，显示错误提示："不支持的文件格式或文件过大"。

3. **特征文件查找**：系统不支持实时特征提取，因此需要查找预提取的特征文件。对于SDK数据集中的样本，特征文件名与视频ID对应。如果找不到特征文件，显示提示："该文件的特征未预提取，请使用其他方式"。

**异常处理**：

输入模块需要处理各种异常情况：
- 空输入：显示"请输入文本或上传文件"
- 无效输入：显示"输入包含无效字符，请检查"
- 网络错误：显示"网络连接失败，请重试"
- 超时：显示"处理超时，请稍后重试"

### 3.2.2 特征提取模块设计

特征提取模块负责将预处理后的数据转换为固定维度的特征向量。这是系统性能的关键环节，特征的质量直接影响最终分类效果。

**文本特征提取**：

文本特征提取使用预训练的GloVe词向量。GloVe（Global Vectors for Word Representation）通过聚合全局词共现统计信息学习词向量，能够捕捉词语之间的语义关系。

**提取流程**：

1. **加载GloVe词向量表**：系统启动时加载预训练的GloVe词向量文件（glove.6B.300d.txt），构建词汇表到向量的映射字典。该文件包含40万条词汇，每条词汇对应300维向量。

2. **分词**：对输入文本进行分词，得到单词列表 $w = [w_1, w_2, ..., w_n]$。

3. **词向量查找**：对每个单词查找对应的词向量 $v_i \in \mathbb{R}^{300}$。如果单词不在GloVe词汇表中（OOV, Out-of-Vocabulary），使用零向量填充。

4. **平均池化**：对词向量序列进行平均池化，得到句子级表示：
   $$ h_{\text{text}} = \frac{1}{n} \sum_{i=1}^{n} v_i $$

5. **L2归一化**：对句子向量进行L2归一化，确保不同长度的文本具有可比性：
   $$ h_{\text{text}} = \frac{h_{\text{text}}}{\|h_{\text{text}}\|_2} $$

**音频特征提取**：

音频特征使用COVAREP（Coherent and Extracted Representation of Audio）工具提取。COVAREP是一个著名的声学特征提取工具，能够提取多种声学特征。

由于COVAREP的配置需要MATLAB环境，涉及多个依赖工具包，本研究使用SDK提供的预提取特征。特征文件为.h5格式，包含74维特征向量。

**特征说明**：

COVAREP的74维特征包括：
- **音高相关**（4维）：F0（基频）、F0包络等
- **谐波噪声比**（1维）：HNR，衡量语音的周期性
- **峰度**（1维）：描述信号分布的形状
- **语音概率**（1维）：判断每一帧是否为语音
- **MFCC系数**（12维）：梅尔频率倒谱系数，描述频谱包络
- **MFCC一阶差分**（12维）：MFCC的动态特征
- **MFCC二阶差分**（12维）：MFCC的加速度特征
- **共振峰频率**（12维）：F1、F2、F3及其动态特征
- **其他特征**（19维）：包括对数能量、频谱倾斜度等

**视频特征提取**：

视频特征使用OpenFace工具提取。OpenFace是一个开源的面部行为分析工具，能够提取多种面部特征。同样，本研究使用SDK提供的预提取特征。

**特征说明**：

OpenFace的710维特征包括：
- **动作单元**（17维）：AU1, AU2, ..., AU17的强度，描述面部肌肉运动
- **头部姿态**（6维）：pitch, yaw, roll及其位置变化
- **面部landmarks**（136维）：68个landmark点的x,y坐标
- **Gaze方向**（6维）：左右眼的gaze向量
- **特征点置信度**（2维）：landmark检测的可信度分数

**特征归一化**：

由于不同模态特征的尺度差异巨大（GloVe约±1，COVAREP约±1000，OpenFace约±100），需要进行归一化。本研究使用L2归一化：

$$ h = \frac{h}{\|h\|_2} $$

归一化后的特征具有单位长度，避免了某个模态因数值过大而主导融合结果。

### 3.2.3 融合推理模块设计

融合推理模块是系统的核心，实现多模态特征的融合和情感预测。该模块包含特征投影、注意力融合和集成预测三个子模块。

**特征投影子模块**：

特征投影的目的是将异构特征投影到统一的语义空间，为后续融合奠定基础。每个模态有独立的MLP编码器：

$$ h_T' = \text{MLP}_{\text{text}}(h_T), \quad h_A' = \text{MLP}_{\text{audio}}(h_A), \quad h_V' = \text{MLP}_{\text{video}}(h_V) $$

其中，$h_T \in \mathbb{R}^{300}$, $h_A \in \mathbb{R}^{74}$, $h_V \in \mathbb{R}^{710}$ 是原始特征，$h_T', h_A', h_V' \in \mathbb{R}^{64}$ 是投影后的特征。

**MLP编码器结构**（以文本为例）：

```python
MLP_text = nn.Sequential(
    nn.Linear(300, 128),
    nn.LayerNorm(128),
    nn.ReLU(),
    nn.Dropout(0.3),
    nn.Linear(128, 64)
)
```

音频和视频编码器结构类似，仅输入维度不同。LayerNorm稳定训练，ReLU引入非线性，Dropout防止过拟合。

**注意力融合子模块**：

注意力融合是核心创新点，使用多头自注意力学习模态间的动态交互关系。

**输入构造**：将三种模态的投影特征堆叠为序列：
$$ H = \text{Stack}(h_T', h_A', h_V') \in \mathbb{R}^{3 \times 64} $$

这里，每个模态被视为序列中的一个"token"，类似于NLP中的一个词。

**多头注意力计算**：

$$ \text{MultiHead}(H) = \text{Concat}(\text{head}_1, ..., \text{head}_h)W^O $$

$$ \text{head}_i = \text{Attention}(HW_i^Q, HW_i^K, HW_i^V) $$

$$ \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V $$

其中，$h=4$ 是头的数量，$d_k = 16$ 是每头的维度（$64/4=16$）。

**聚合**：多头注意力的输出是形状为$(3, 64)$的张量，通过平均聚合得到最终的融合特征：
$$ h_{\text{fused}} = \frac{1}{3} \sum_{i=1}^{3} H_i' \in \mathbb{R}^{64} $$

**集成预测子模块**：

集成预测组合两个基模型的预测结果，通过加权软投票得到最终预测。

**基模型推理**：
- 模型1（S3+S4）：使用类别权重的注意力融合模型
- 模型2（S3）：不使用类别权重的注意力融合模型

每个基模型输出三类的概率分布：$p^1 = [p^1_1, p^1_2, p^1_3]$, $p^2 = [p^2_1, p^2_2, p^2_3]$。

**加权投票**：
$$ p = w_1 \cdot p^1 + w_2 \cdot p^2 $$

其中，$w_1 = 1.5$, $w_2 = 1.0$ 是通过网格搜索确定的最优权重。

**最终预测**：
$$ \hat{y} = \arg\max_c \, p_c $$

### 3.2.4 输出展示模块设计

输出展示模块负责将预测结果渲染为用户可见的界面元素，包括文本信息和可视化图表。

**文本信息展示**：

1. **情感类别标签**：显示预测的情感类别，使用不同颜色区分：
   - Negative：红色
   - Neutral：灰色
   - Positive：绿色

2. **置信度分数**：显示预测类别的概率值，例如：
   > "置信度：78.5%"

3. **辅助说明**：提供简要的类别解释：
   - Negative：消极、负面情感
   - Neutral：中性、无明显情感倾向
   - Positive：积极、正面情感

**可视化图表生成**：

使用Matplotlib生成概率分布柱状图：

```python
import matplotlib.pyplot as plt

categories = ['Negative', 'Neutral', 'Positive']
probabilities = [p[0], p[1], p[2]]
colors = ['#E74C3C', '#95A5A6', '#2ECC71']

plt.figure(figsize=(8, 4))
bars = plt.bar(categories, probabilities, color=colors)
plt.ylabel('Probability')
plt.title('Sentiment Probability Distribution')
plt.ylim(0, 1)

# 在柱状图上显示数值
for bar, prob in zip(bars, probabilities):
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height,
             f'{prob:.3f}', ha='center', va='bottom')

plt.tight_layout()
```

生成的图表通过Streamlit的`st.pyplot()`函数嵌入到Web界面。

---

## 3.3 界面设计

### 3.3.1 主界面布局

系统采用单页应用（SPA）设计，所有功能在一个页面内完成。主界面分为侧边栏和主内容区两部分。

**侧边栏**（左侧，宽度25%）：

侧边栏提供系统信息和配置选项：

```
┌─────────────────────┐
│  多模态情感分析系统   │
│  ─────────────────  │
│                     │
│  📊 模型信息         │
│  - 模型：S7-v1      │
│  - 版本：v1.0        │
│  - 准确率：59.47%    │
│                     │
│  ⚙️ 系统配置         │
│  - 显示详细结果      │
│  ☑  启用            │
│                     │
│  📖 使用说明         │
│  1. 输入文本...      │
│  2. 点击分析...      │
│  3. 查看结果...      │
│                     │
└─────────────────────┘
```

**主内容区**（右侧，宽度75%）：

主内容区分为上下两部分：

**上半部分 - 输入区域**：

```
┌─────────────────────────────────────────────────────┐
│  📝 文本输入                                        │
│  ┌───────────────────────────────────────────────┐  │
│  │                                               │  │
│  │  请输入要分析的文本内容...                      │  │
│  │                                               │  │
│  │                                               │  │
│  └───────────────────────────────────────────────┘  │
│                                                     │
│  [📁 上传音频]  [🎬 上传视频]                        │
│                                                     │
│  [          🚀 开始分析          ]                  │
└─────────────────────────────────────────────────────┘
```

**下半部分 - 结果展示区域**：

```
┌─────────────────────────────────────────────────────┐
│  📊 分析结果                                        │
│  ┌───────────────────────────────────────────────┐  │
│  │                                               │  │
│  │   预测情感：Positive  (置信度: 78.5%)         │  │
│  │                                               │  │
│  │   ┌─────────────────────────────────────┐    │  │
│  │   │  Sentiment Probability Distribution  │    │  │
│  │   │                                     │    │  │
│  │   │  Neg ┐                               │    │  │
│  │   │      █                               │    │  │
│  │   │      █  Neu ┐                       │    │  │
│  │   │      █      █                       │    │  │
│  │   │      █      █  Pos ┐                │    │  │
│  │   │      █      █      ███               │    │  │
│  │   │      █      █      █████             │    │  │
│  │   └─────────────────────────────────────┘    │  │
│  │                                               │  │
│  │   Negative: 0.085  Neutral: 0.130  Pos: 0.785│  │
│  │                                               │  │
│  └───────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────┘
```

### 3.3.2 交互流程设计

系统的交互流程设计为六步，确保用户体验流畅：

**步骤1：用户输入**

用户在输入区域输入文本或上传文件。输入框支持多行文本，最多500字符。对于音频/视频上传，系统显示文件名和大小，确认上传成功。

**步骤2：点击分析**

用户点击"🚀 开始分析"按钮，触发分析流程。系统进行以下验证：
- 检查输入是否为空
- 检查文本长度是否合理
- 检查上传文件格式是否正确

如果验证失败，显示错误提示；如果验证成功，进入下一步。

**步骤3：显示加载状态**

系统显示加载动画和提示文字："正在分析，请稍候..."。这告诉用户系统正在处理，避免用户重复点击。

**步骤4：后台处理**

后台执行特征提取和模型推理：
1. 文本分词和GloVe查找（<10ms）
2. MLP编码和注意力融合（<50ms）
3. 集成模型推理（<50ms）
4. 概率分布计算（<10ms）

总处理时间约100-200ms，用户感知的延迟很小。

**步骤5：显示结果**

后台处理完成后，系统更新界面，展示分析结果：
- 情感类别标签（带颜色）
- 置信度分数
- 概率分布柱状图

结果区域从空白状态平滑过渡到结果展示状态。

**步骤6：继续操作**

用户可以选择：
- 修改输入文本，重新分析
- 清空输入，开始新的分析
- 查看模型详细信息和系统说明

### 3.3.3 可视化设计

可视化是结果展示的重要组成部分，良好的可视化能够帮助用户直观理解分析结果。

**颜色方案**：

本研究采用直观的颜色编码：
- **Negative（消极）**：红色 #E74C3C
- **Neutral（中性）**：灰色 #95A5A6
- **Positive（积极）**：绿色 #2ECC71

这些颜色符合人们对情感的直觉认知（红色表示负面，绿色表示正面）。

**概率分布图设计**：

概率分布图采用垂直柱状图，包含以下要素：

1. **标题**："Sentiment Probability Distribution"，清晰说明图表内容

2. **坐标轴**：
   - X轴：三个情感类别
   - Y轴：概率值（0到1）

3. **柱状条**：
   - 不同类别使用不同颜色
   - 柱状条高度对应概率值
   - 柱状条顶部显示精确概率值（保留3位小数）

4. **网格线**：添加水平网格线，便于比较不同类别的概率

5. **图例**：在图表右上角添加图例，说明颜色与类别的对应关系

**响应式设计**：

界面采用响应式设计，适配不同屏幕尺寸：
- **桌面端**（>1024px）：侧边栏+主内容区布局
- **平板端**（768-1024px）：侧边栏可折叠，主内容区全宽
- **移动端**（<768px）：单列布局，侧边栏移至底部

---

**[第三章完成]**

**字数统计**: 约5,500字

**架构图**: 1个系统分层架构图

**流程图**: 4个数据处理流程图

**界面设计**: 完整的UI布局和交互流程
