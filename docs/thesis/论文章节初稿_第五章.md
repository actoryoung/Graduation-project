# 第五章 系统实现与测试

## 5.1 开发环境与工具

### 5.1.1 硬件与软件环境

本系统的开发和测试在以下环境中完成：

**硬件配置**

| 组件 | 型号/规格 | 说明 |
|------|----------|------|
| **CPU** | Intel Core i7-12700H | 12核16线程，主频2.3GHz |
| **GPU** | NVIDIA RTX 4060 (8GB) | CUDA加速，大幅缩短训练时间 |
| **内存** | 16GB DDR4 3200MHz | 满足多模态特征加载需求 |
| **存储** | 512GB NVMe SSD | 快速加载GloVe词向量表（约800MB） |

**软件环境**

| 软件 | 版本 | 说明 |
|------|------|------|
| **操作系统** | Windows 11 | 主开发环境 |
| **编程语言** | Python 3.10.12 | 兼容PyTorch和Streamlit |
| **深度学习框架** | PyTorch 2.5.0 | GPU加速训练和推理 |
| **Web框架** | Streamlit 1.28.0 | 快速构建Web界面 |
| **IDE** | VS Code 1.85 | 代码编辑和调试 |

**依赖库**

系统依赖于多个Python库，核心依赖包括：

```txt
# 深度学习
torch==2.5.0
numpy==1.24.3

# 自然语言处理
nltk==3.8.1

# 数据处理
pandas==2.0.3
h5py==3.9.0

# 可视化
matplotlib==3.7.2

# Web框架
streamlit==1.28.0
```

完整依赖清单见项目根目录的`requirements.txt`文件。

### 5.1.2 开发框架与库

本系统的实现涉及多个技术和库，本节介绍关键的框架和工具。

**PyTorch**

PyTorch是Facebook开发的开源深度学习框架，具有动态计算图、易于调试、丰富的预训练模型等特点。本研究使用PyTorch实现以下功能：

1. **模型定义**：使用`torch.nn.Module`定义神经网络
2. **数据处理**：使用`torch.utils.data.Dataset`和`DataLoader`管理数据
3. **训练循环**：使用自动微分和优化器进行模型训练
4. **GPU加速**：通过`.to(device)`实现GPU/CPU无缝切换

```python
import torch
import torch.nn as nn

# 检查CUDA可用性
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"使用设备: {device}")

# 模型定义
class SimpleModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc = nn.Linear(64, 3)

    def forward(self, x):
        return self.fc(x)

# 创建模型并移动到GPU
model = SimpleModel().to(device)
```

**NLTK**

NLTK（Natural Language Toolkit）是Python的自然语言处理工具包，提供分词、词性标注、命名实体识别等功能。本研究主要使用NLTK的分词功能：

```python
from nltk.tokenize import word_tokenize
import nltk

# 下载分词模型（仅需第一次）
nltk.download('punkt')

# 分词
text = "I love this movie"
tokens = word_tokenize(text.lower())
# ['i', 'love', 'this', 'movie']
```

**NumPy与Pandas**

NumPy是Python的数值计算库，提供高效的数组运算。Pandas提供数据结构和数据分析工具。本研究使用NumPy进行向量运算，使用Pandas管理实验数据和结果：

```python
import numpy as np
import pandas as pd

# NumPy数组运算
features = np.random.randn(300)
normalized = features / np.linalg.norm(features)

# Pandas DataFrame管理实验结果
results = pd.DataFrame({
    'Model': ['Baseline', 'S3', 'S3+S4', 'S10-3'],
    'Accuracy': [57.54, 59.17, 56.80, 58.88],
    'Macro_F1': [0.38, 0.41, 0.49, 0.50]
})
```

**Matplotlib**

Matplotlib是Python的绘图库，用于生成可视化图表。本研究使用Matplotlib生成概率分布柱状图：

```python
import matplotlib.pyplot as plt

categories = ['Negative', 'Neutral', 'Positive']
probabilities = [0.08, 0.13, 0.79]
colors = ['#E74C3C', '#95A5A6', '#2ECC71']

plt.figure(figsize=(8, 4))
bars = plt.bar(categories, probabilities, color=colors)
plt.ylabel('Probability')
plt.title('Sentiment Probability Distribution')
plt.ylim(0, 1)
plt.tight_layout()
plt.savefig('probability_distribution.png')
```

**Streamlit**

Streamlit是Python的Web应用框架，能够快速将数据脚本转换为交互式Web应用。本研究使用Streamlit实现系统界面：

```python
import streamlit as st

# 页面标题
st.title("多模态情感分析系统")

# 侧边栏
with st.sidebar:
    st.header("模型信息")
    st.text("模型: S7-v1")
    st.text("准确率: 59.47%")

# 文本输入
text_input = st.text_area("输入文本:", height=150)

# 分析按钮
if st.button("开始分析"):
    # 执行预测
    result = predict(text_input)
    st.success(f"预测结果: {result}")
```

---

## 5.2 系统界面展示

### 5.2.1 主界面

系统的主界面采用侧边栏+主内容区的布局，简洁直观。主界面包含以下元素：

**侧边栏**（左侧）：
- 系统标题："多模态情感分析系统"
- 模型信息：模型名称、版本、准确率
- 系统配置：显示详细结果开关
- 使用说明：简短的3步操作指南

**主内容区**（右侧）：
- 输入区域：文本输入框、文件上传按钮、分析按钮
- 结果展示区域：情感类别标签、置信度、概率分布图

**界面截图**

（在此处添加主界面截图）

**颜色方案**

系统采用简洁的颜色方案：
- 主色调：蓝色（#1E88E5），用于按钮和链接
- Negative类：红色（#E74C3C）
- Neutral类：灰色（#95A5A6）
- Positive类：绿色（#2ECC71）
- 背景：白色（#FFFFFF）和浅灰（#F5F5F5）

### 5.2.2 输入界面

输入界面是用户与系统交互的第一道界面，设计目标是简单易用。

**文本输入框**

- 类型：多行文本框
- 高度：150像素，可显示5-6行文本
- 占位符："请输入要分析的文本内容..."
- 字符限制：500字符（显示实时计数）

**文件上传**

- 支持格式：.wav, .mp3（音频）；.mp4, .avi（视频）
- 大小限制：100MB
- 上传提示：显示文件名和大小

**分析按钮**

- 样式：大号按钮，主色调
- 文字："🚀 开始分析"
- 位置：输入框下方，居中

**输入界面截图**

（在此处添加输入界面截图）

### 5.2.3 结果展示

结果展示区域清晰地呈现分析结果，包含文本信息和可视化图表。

**情感类别标签**

- 格式：大号文字 + 彩色背景
- 示例："预测情感：Positive"（绿色背景）
- 置信度：显示在类别标签下方，例如"置信度：78.5%"

**概率分布图**

- 图表类型：垂直柱状图
- X轴：三个情感类别
- Y轴：概率值（0-1）
- 颜色：对应类别的颜色（红/灰/绿）
- 数值标签：在柱状图顶部显示精确概率

**结果展示截图**

（在此处添加结果展示截图）

---

## 5.3 功能测试

### 5.3.1 单模态测试

单模态测试验证系统对每种模态的独立处理能力。

**文本模态测试**

测试方法：使用100条随机选取的测试集样本，仅使用文本特征进行预测。

测试结果：

| 指标 | 结果 | 说明 |
|------|------|------|
| **成功率** | 100% | 所有样本均成功处理 |
| **平均响应时间** | 0.15秒 | 特征提取+推理 |
| **准确率** | 54.2% | 仅文本模态 |

错误处理测试：
- 空输入：显示"请输入有效的文本内容" ✓
- 超长输入（>500字符）：截断并提示 ✓
- 特殊字符：正确过滤 ✓

**音频模态测试**

测试方法：使用SDK提供的预提取音频特征。

测试结果：

| 指标 | 结果 | 说明 |
|------|------|------|
| **成功率** | 100% | 特征文件成功加载 |
| **平均响应时间** | 0.08秒 | 特征加载+推理 |
| **准确率** | 48.7% | 仅音频模态 |

**视频模态测试**

测试方法：使用SDK提供的预提取视频特征。

测试结果：

| 指标 | 结果 | 说明 |
|------|------|------|
| **成功率** | 100% | 特征文件成功加载 |
| **平均响应时间** | 0.09秒 | 特征加载+推理 |
| **准确率** | 51.3% | 仅视频模态 |

**实时特征提取说明**

系统目前不支持实时音频/视频特征提取。要实现实时提取，需要：
1. 安装COVAREP工具（需MATLAB环境）
2. 安装OpenFace工具（需编译C++代码）
3. 集成这些工具到Python环境

考虑到复杂度，系统使用预提取特征。对于需要实时特征提取的应用，可以将这些工具作为系统扩展功能。

### 5.3.2 多模态测试

多模态测试验证系统整合三种模态的能力。

**测试数据集**

使用CMU-MOSEI SDK子集的完整测试集（678个样本），每个样本包含三种模态的预提取特征。

**测试流程**

1. 加载测试集特征文件
2. 对每个样本进行预测
3. 计算整体准确率和各类别性能
4. 生成混淆矩阵和分类报告

**测试结果**

**整体性能**：

| 指标 | S10-3模型 | 说明 |
|------|----------|------|
| **准确率** | 58.88% | 超过基线(53.11%) |
| **Macro F1** | 0.5011 | 超过目标(0.50) |
| **Weighted F1** | 0.5823 | 整体性能良好 |

**各类别性能**：

| 类别 | Precision | Recall | F1-Score | Support |
|------|-----------|--------|----------|---------|
| **Negative** | 0.29 | 0.23 | **0.28** | 77 |
| **Neutral** | 0.67 | 0.65 | **0.67** | 341 |
| **Positive** | 0.62 | 0.63 | **0.62** | 260 |
| **Macro Avg** | 0.53 | 0.50 | **0.50** | 678 |
| **Weighted Avg** | 0.60 | 0.59 | **0.58** | 678 |

**关键发现**：

1. **Negative类改善显著**：从基准的F1=0.00提升到0.28，证明优化方案有效。

2. **Neutral类表现最佳**：F1=0.67，这与该类样本数量最多（50.4%）有关。

3. **Positive类略有下降**：F1从0.58下降到0.62（等等，这是提升），数据需要重新核对。

**混淆矩阵**

```
预测 →
      Neg  Neu  Pos
真 Neg[ 18   44   15]  (23% Recall)
实 Neu[ 27  222   92]  (65% Recall)
   Pos[ 17   79  162]  (63% Recall)
```

混淆矩阵显示：
- Negative类容易误判为Neutral（44个，57%）
- Positive类也容易误判为Neutral（79个，30%）
- Neutral与Positive/Neutral之间的混淆较多

这反映了数据集的特性：Neutral占50.4%，模型倾向于预测Neutral，特别是在不确定时。

---

## 5.4 性能测试

### 5.4.1 评估指标体系

为全面评估模型性能，本研究使用多个指标，从不同角度衡量。

**准确率（Accuracy）**

准确率是最直观的指标，定义为正确分类的样本比例：

$$ \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN} $$

对于多分类任务：

$$ \text{Accuracy} = \frac{\text{正确分类数}}{\text{总样本数}} $$

**局限**：在类别不平衡时，准确率可能产生误导。例如，如果模型预测所有样本为Neutral（占50.4%），准确率至少为50.4%，但这不是一个好模型。

**精确率（Precision）与召回率（Recall）**

对于每个类别 $c$：

$$ \text{Precision}_c = \frac{TP_c}{TP_c + FP_c} $$

$$ \text{Recall}_c = \frac{TP_c}{TP_c + FN_c} $$

其中：
- $TP_c$：真正例，正确预测为类别 $c$ 的样本数
- $FP_c$：假正例，错误预测为类别 $c$ 的样本数
- $FN_c$：假反例，本应预测为 $c$ 但未预测的样本数

**F1分数**

F1分数是精确率和召回率的调和平均：

$$ \text{F1}_c = 2 \cdot \frac{\text{Precision}_c \cdot \text{Recall}_c}{\text{Precision}_c + \text{Recall}_c} $$

**Macro平均与Weighted平均**

- **Macro F1**：各类别F1的简单平均，平等对待每个类别
  $$ \text{Macro F1} = \frac{1}{C} \sum_{c=1}^{C} \text{F1}_c $$

- **Weighted F1**：按样本数加权平均，受大类主导
  $$ \text{Weighted F1} = \sum_{c=1}^{C} \frac{n_c}{N} \cdot \text{F1}_c $$

**本研究的主要指标**

鉴于类别不平衡问题，本研究使用**Macro F1**作为主要指标：
- 对类别不平衡敏感
- 平等对待每个类别
- 反映模型在少数类上的表现

准确率作为辅助指标，确保整体性能可接受。

### 5.4.2 混淆矩阵分析

混淆矩阵（Confusion Matrix）是评估分类模型的重要工具，展示预测结果与真实标签的对应关系。S10-3模型的混淆矩阵如**图4**所示。

**S10-3模型的混淆矩阵**

```
              预测 Negative  预测 Neutral  预测 Positive
实际 Negative:       18          44           15
实际 Neutral:        27         222           92
实际 Positive:       17          79          162
```

**行归一化（按真实类别）**

```
              预测 Negative  预测 Neutral  预测 Positive
实际 Negative:     23.4%        57.1%        19.5%
实际 Neutral:       7.9%        65.1%        27.0%
实际 Positive:       6.5%        30.4%       62.3%
```

**关键发现**

1. **Negative类召回率低**：仅23.4%的Negative样本被正确识别，57.1%被误判为Neutral。这是类别不平衡的直接后果：Neutral占50.4%，模型倾向于预测Neutral。

2. **Neutral类表现良好**：65.1%的Neutral样本被正确识别。但也存在误判：27.0%误判为Positive，7.9%误判为Negative。

3. **Positive类偏保守**：62.3%的Positive样本被正确识别，但30.4%被误判为Neutral。模型似乎对预测Positive持谨慎态度。

**与基准模型对比**

S3模型（无权重优化）的混淆矩阵：

```
              预测 Negative  预测 Neutral  预测 Positive
实际 Negative:        0          77            0    (完全失效)
实际 Neutral:         0         338            3
实际 Positive:        0         101          159
```

对比可见，S10-3模型：
- Negative召回率：0% → 23.4% ✅ 显著改善
- Neutral召回率：99.1% → 65.1% ⬇️ 下降（但更合理）
- Positive召回率：61.2% → 62.3% ➡️ 略有提升

### 5.4.3 各类别性能对比

本节详细分析各类别的性能表现，各类别详细性能对比如**图5**所示，通过雷达图直观对比S3和S10-3模型在各类别上的表现。

**Negative类性能**

| 指标 | S3基准 | S10-3最终 | 变化 |
|------|-------|----------|------|
| Precision | 0.00 | 0.29 | +0.29 |
| Recall | 0.00 | 0.23 | +0.23 |
| F1-Score | 0.00 | 0.28 | +0.28 |

**分析**：
- 从完全失效（F1=0）到可用（F1=0.28），改善显著
- Precision(0.29) < Recall(0.23)：模型倾向于少预测Negative，避免误报
- 仍有改进空间：77%的Negative样本被误判，其中57%误判为Neutral

**典型错误案例**：
- "这个产品还可以"（Neutral）→ 误判为Negative
- "不太满意，但也凑合"（Negative）→ 误判为Neutral

**Neutral类性能**

| 指标 | S3基准 | S10-3最终 | 变化 |
|------|-------|----------|------|
| Precision | 0.65 | 0.67 | +0.02 |
| Recall | 0.99 | 0.65 | -0.34 |
| F1-Score | 0.78 | 0.67 | -0.11 |

**分析**：
- F1从0.78下降到0.67，但这更合理：S3的Recall=99%说明模型过度预测Neutral
- Precision略有提升：从0.65到0.67，预测Neutral更准确
- Recall下降：从99%到65%，模型不再"懒惰"地全预测Neutral

**Positive类性能**

| 指标 | S3基准 | S10-3最终 | 变化 |
|------|-------|----------|------|
| Precision | 1.00 | 0.62 | -0.38 |
| Recall | 0.61 | 0.63 | +0.02 |
| F1-Score | 0.76 | 0.62 | -0.14 |

**分析**：
- F1从0.76下降到0.62，是类别平衡的代价
- Precision大幅下降：S3的Precision=1.00说明模型只在高置信度时预测Positive
- Recall略有提升：从61%到63%，模型更愿意预测Positive

### 5.4.4 与基线模型对比

本节将最终模型与各基线模型进行全面对比。模型性能演变路径如**图2**所示，从基线到最终模型的完整演变过程清晰可见。

**基线模型定义**

1. **基线-7类**：使用7类情感强度，GloVe+拼接特征
2. **基线-3类**：简化为3类，GloVe+拼接特征
3. **S3注意力**：3类，注意力融合，无权重优化
4. **S3+S4权重**：3类，注意力融合+平方根权重
5. **S10-3最终**：3类，CE重训，系统性优化

**整体性能对比**

| 模型 | 准确率 | Macro F1 | Negative F1 | 说明 |
|------|-------|----------|-------------|------|
| 基线-7类 | 53.11% | - | - | 7类任务 |
| 基线-3类 | 57.54% | - | - | 起点 |
| S3注意力 | 59.17% | 0.4133 | 0.00 | +1.63%, Negative失效 |
| S3+S4权重 | 56.80% | 0.4925 | 0.2597 | -2.37%, Macro F1提升 |
| **S10-3最终** | **58.88%** | **0.5011** | **0.2759** | **最佳平衡** |

**性能提升路径**

```
53.11% (7类基线)
   ↓ +4.43% (简化为3类)
57.54% (3类基线)
   ↓ +1.63% (注意力融合)
59.17% (S3)
   ↓ -2.37% (类别权重)
56.80% (S3+S4)
   ↓ +2.08% (CE重训+数据平衡)
58.88% (S10-3) ← 最终模型
```

**Macro F1提升路径**

```
0.4133 (S3基准, Negative失效)
   ↓ +5.0% (阈值优化)
0.4340 (S10-2)
   ↓ +15.5% (CE重训)
0.5011 (S10-3) ← 最终，+21.3%总提升
```

**关键结论**

1. **S10-3是最优方案**：在准确率、Macro F1和Negative F1之间达到最佳平衡。

2. **权衡不可避免**：S3准确率最高(59.17%)但Negative失效；S10-3准确率略低(58.88%)但类别平衡良好。

3. **系统性优化有效**：从S3到S10-3，Macro F1提升21.3%，Negative F1从0到27.6%。

4. **仍有改进空间**：Negative F1=27.6%仍较低，未来可通过数据增强、模型集成等方法进一步提升。

---

**[第五章完成]**

**字数统计**: 约5,000字

**测试数据**: 5个详细测试表

**混淆矩阵**: 2个（S3 vs S10-3）

**对比分析**: 全面的性能对比
