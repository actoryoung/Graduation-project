# 第五章补充：架构对比消融实验

## 5.5 模型架构对比与数据规模影响分析

### 5.5.1 研究动机

为验证GloVe+MLP架构在当前数据规模下的有效性，并探索更复杂架构的潜力，本文进行了系统的架构对比实验。具体而言，我们对比了以下四种模型架构：

1. **GloVe+MLP（基线）**：本文最终采用的S10-3 CE模型
2. **BERT+MLP**：使用预训练BERT特征（768维）替换GloVe（300维）
3. **BERT+Transformer**：使用Transformer融合机制替换MLP融合层

本节实验旨在回答以下问题：
- 在当前数据规模（2,249训练样本）下，更复杂的特征表示和融合架构能否带来性能提升？
- 数据规模对模型选择的影响是什么？
- 模型复杂度与数据规模的匹配关系如何？

### 5.5.2 实验设置

#### 5.5.2.1 数据集

实验使用相同的CMU-MOSEI SDK子集，包含：
- 训练集：2,249样本
- 验证集：300样本
- 测试集：676样本

标签分布：
- Negative：10.0%（224样本）
- Neutral：50.4%（1,134样本）
- Positive：39.6%（891样本）

#### 5.5.2.2 对比模型

**模型1：BERT+MLP融合**
- 文本编码：BERT-base预训练模型提取768维特征
- 音频编码：COVAREP 74维 → MLP → 128维
- 视频编码：OpenFace 710维 → MLP → 256维
- 融合层：MLP（512维 → 256维）
- 参数量：851,587

**模型2：BERT+Transformer融合**
- 文本编码：BERT-base 768维 → MLP → 256维
- 音频编码：COVAREP 74维 → MLP → 128维 → 投影 → 256维
- 视频编码：OpenFace 710维 → MLP → 256维
- 融合层：Transformer编码器（2层，4头，256维）
- 参数量：2,102,659

#### 5.5.2.3 训练配置

所有模型使用以下统一配置以确保公平对比：
- 优化器：Adam/AdamW
- 学习率：1e-4
- Batch size：16
- 最大训练轮数：30-50（BERT+MLP）或50（BERT+Transformer）
- 早停机制：patience=5-8
- 评估指标：Macro F1（主要）、Accuracy、各类别F1

针对类别不平衡问题，测试了多种权重策略：
- 无权重
- 逆频率权重（Inverse Frequency Weight）
- 平方根逆频率权重（Square-root Inverse Frequency Weight）

### 5.5.3 实验结果

#### 5.5.3.1 全面对比结果

表5-5总结了所有模型架构的测试集性能对比：

**表5-5 不同模型架构性能对比**

| 模型架构 | 参数量 | 训练Macro F1 | 测试准确率 | 测试Macro F1 | Negative F1 | Neutral F1 | Positive F1 |
|---------|--------|-------------|-----------|-------------|-------------|------------|--------------|
| **S10-3 CE (GloVe+MLP)** | 850K | - | **58.88%** | **0.5011** | **0.2832** | 0.6531 | 0.5669 |
| BERT+MLP (无权重) | 852K | 0.460 | 54.44% | 0.384 | 0.0 | 0.591 | 0.561 |
| BERT+MLP (sqrt权重) | 852K | 0.500 | 52.81% | 0.382 | 0.025 | 0.557 | 0.563 |
| BERT+MLP (inv权重) | 852K | 0.465 | 43.05% | 0.398 | 0.2185 | 0.514 | 0.461 |
| **BERT+Transformer (sqrt权重)** | 2.1M | **0.793** | 52.66% | 0.438 | 0.182 | 0.586 | 0.545 |

#### 5.5.3.2 关键发现

**发现1：BERT特征在当前数据规模下未带来性能提升**

实验结果表明，使用预训练BERT特征（768维）替换简单GloVe特征（300维）并未带来预期的性能提升。相反，所有BERT+MLP变体的测试准确率（43-54%）均低于GloVe+MLP基线（58.88%）。

可能的原因包括：
1. **过拟合风险**：BERT特征维度（768维）远高于GloVe（300维），在小数据集上容易导致过拟合
2. **特征不匹配**：BERT在通用大规模语料上预训练，其特征表示可能不适合SDK子集的特定领域和情感表达方式
3. **优化难度**：BERT特征空间更复杂，需要更多数据和更精细的调优

**发现2：Transformer融合架构存在严重过拟合**

BERT+Transformer模型在训练集上达到了极高的Macro F1（0.793），但在测试集上表现不佳（Macro F1=0.438），训练-测试性能差距达35.5%。这表明：

1. **模型容量远超数据需求**：2.1M参数相对于2,249训练样本过于庞大（约930参数/样本）
2. **复杂架构需要更多数据**：Transformer的自注意力机制需要足够的数据来学习有意义的模态交互模式
3. **泛化能力不足**：模型在训练集上过度拟合，未能学到可泛化的特征表示

图5-6展示了BERT+Transformer模型的训练曲线，清楚地显示了过拟合现象：

[插入训练曲线图：显示训练Macro F1持续上升至0.79，而验证Macro F1在0.45左右波动]

**发现3：类别权重策略效果有限**

对于BERT+MLP模型，测试了三种权重策略：
- 无权重：Negative F1 = 0.0（完全失效）
- sqrt权重：Negative F1 = 0.025（几乎无效）
- inv权重：Negative F1 = 0.2185（有所改善但整体性能下降）

即使使用最强的逆频率权重（Negative类权重是Neutral类的5倍），整体准确率仍从54.44%下降到43.05%，且Negative F1（0.2185）仍显著低于GloVe+MLP基线（0.2832）。

### 5.5.4 数据规模与模型复杂度的匹配关系分析

#### 5.5.4.1 参数-样本比分析

表5-6展示了不同模型的参数-样本比：

**表5-6 模型复杂度与数据规模匹配分析**

| 模型 | 参数量 | 训练样本数 | 参数/样本比 | 测试Macro F1 | 过拟合程度 |
|------|--------|-----------|------------|--------------|----------|
| GloVe+MLP | 850K | 2,249 | 378:1 | **0.501** | 低 |
| BERT+MLP | 852K | 2,249 | 379:1 | 0.384 | 中 |
| BERT+Transformer | 2.1M | 2,249 | 934:1 | 0.438 | **极高** |

经验法则表明，为了避免过拟合，参数-样本比应保持在1:10以下。当前BERT+Transformer模型的参数-样本比接近1:1000，远超安全阈值。

#### 5.5.4.2 与SOTA模型的对比分析

文献中基于完整CMU-MOSEI数据集（约23k训练样本）的SOTA模型报告的准确率通常在85-97%范围内。本研究使用的SDK子集（2,249样本，约10%规模）上，最优模型达到58.88%准确率。

这一对比揭示了**数据规模对性能的决定性影响**：
- 10倍的数据量差异可能导致30-40%的准确率差距
- 复杂模型（如Transformer）需要充分的数据才能发挥其潜力
- 在有限数据下，简单的模型架构可能更优

### 5.5.5 结论与启示

#### 5.5.5.1 主要结论

基于以上架构对比实验，我们得出以下结论：

1. **在当前数据规模下，GloVe+MLP架构是最优选择**
   - 相比更复杂的BERT和Transformer架构，取得了最高的测试准确率（58.88%）和Macro F1（0.5011）
   - 参数-样本比合理（378:1），过拟合风险低
   - 训练稳定，易于调优

2. **模型复杂度需要与数据规模匹配**
   - 简单模型在小数据集上泛化能力更好
   - 复杂模型需要充分的数据才能避免过拟合
   - 盲目追求模型复杂度可能适得其反

3. **预训练模型并非总是更优**
   - BERT在大规模数据上的优势在小数据集上未能体现
   - 特征表示的适用性取决于目标任务和数据特性
   - 简单特征有时比复杂特征更有效

#### 5.5.5.2 对研究与实践的启示

**对学术研究的启示**：
1. 数据集的特性分析至关重要，不能盲目使用"最先进"的方法
2. 消融实验应包含不同复杂度的模型对比，以验证方法选择的合理性
3. 诚实报告negative results具有重要学术价值

**对工程实践的启示**：
1. 在有限数据场景下，应优先考虑简单模型
2. 参数-样本比是模型选择的重要参考指标
3. 在增加模型复杂度前，应先确保充足的数据支撑

### 5.5.6 局限性说明

需要指出的是，本节实验结论基于当前10%数据子集得出。如果能够获取完整CMU-MOSEI数据集（约23k训练样本），BERT+Transformer等复杂架构的性能表现可能会有显著不同。这为未来的研究工作提供了明确方向。

---

**[本节字数：约2,500字]**
