# 第一章 绪论

## 1.1 研究背景与意义

### 1.1.1 多模态情感分析的应用需求

随着互联网技术的快速发展和社交媒体的普及，人们表达情感和观点的方式日益多样化。从传统的文本评论到短视频平台，从博客文章到直播互动，用户通过文字、语音、图像、视频等多种形式表达自己的情感和态度。据统计，YouTube每分钟上传超过500小时的视频内容[1]，TikTok日活跃用户超过10亿[2]，微博平台每天产生数亿条 multimodal 内容。这些海量数据中蕴含着丰富的情感信息，对舆情监控、产品反馈分析、用户体验优化等领域具有重要价值。

情感分析（Sentiment Analysis）作为自然语言处理的重要分支，旨在自动识别和提取文本中的情感倾向。然而，传统的单模态情感分析仅依赖文本信息，存在明显的局限性。心理学研究表明，在面对面的情感交流中，语言内容仅传递7%的信息，而语调传递38%，面部表情和肢体语言传递55%[3]。这意味着，如果仅分析文本内容，将丢失超过90%的情感信息。因此，整合文本、音频、视觉多模态信息的多模态情感分析成为学术界和工业界的研究热点。

### 1.1.2 社交媒体情感识别的挑战

尽管多模态情感分析具有重要价值，但在实际应用中面临诸多挑战。

**模态异构性挑战**：不同模态具有不同的表示空间和统计特性。文本是离散的符号序列，音频是连续的一维信号，视频是高维的图像序列。如何将这些异构特征映射到统一的语义空间进行融合，是多模态学习的首要难题。

**模态对齐挑战**：在多模态数据中，不同模态的元素之间需要建立时序或语义对应关系。例如，视频中的某个面部表情应该与音频中的特定语调片段和文本中的某个词语相关联。然而，实际数据中这种对齐关系往往不明确或存在噪声。

**模态互补性与冗余性**：不同模态可能提供互补信息（如视觉表情揭示讽刺意味），也可能存在冗余信息（如文本和语音表达相同情感）。如何设计融合策略以充分利用互补性同时避免冗余信息的过度影响，是一个关键问题。

**模态缺失问题**：在实际应用中，某些模态可能不可用。例如，用户可能只上传图片而没有文字说明，或者视频质量较差导致音频信息无法提取。系统需要具备处理模态缺失的能力。

### 1.1.3 类别不平衡问题的普遍性

在实际的情感分析数据集中，标签分布往往存在严重的不平衡现象。这种不平衡可能源于多个因素：1）数据采集偏差，某些情感类型更容易收集；2）标注者倾向，标注者可能倾向于某些中性标签；3）自然分布，在真实场景中某些情感类型确实更常见。

以CMU-MOSEI数据集[4]的SDK标准子集为例，本研究发现该子集的标签分布存在严重不平衡：Neutral（中性）情感占50.4%，Positive（积极）占39.6%，而Negative（消极）仅占10.0%，如**图1**所示。这种不平衡分布会对模型训练产生显著影响：模型会过度预测多数类（Neutral），而忽视少数类（Negative），导致少数类的识别性能严重下降。

更严重的是，在某些情况下少数类可能完全失效。本研究在使用标准交叉熵训练注意力融合模型时，发现Negative类的F1分数为0，意味着模型完全没有预测任何样本为Negative类。这对于实际应用是不可接受的，因为识别消极情感（如投诉、不满、批评）往往比识别中性情感更具价值。

因此，如何在保持整体性能的同时提升少数类的识别能力，是本研究需要解决的核心问题。

---

## 1.2 国内外研究现状

### 1.2.1 多模态融合策略研究

多模态融合策略是多模情感分析的核心技术，根据融合时机的不同，可分为早期融合、中期融合和晚期融合三类。

**早期融合（Early Fusion）**，又称特征级融合，是最直接的融合方式。该方法在特征层面直接拼接多模态特征，形成统一的高维特征向量，然后输入到分类器。早期融合的优点是实现简单、计算高效，缺点是无法学习模态间的动态关系，所有时刻使用相同的融合方式。Poria等人[5]最早使用早期融合方法进行多模态情感分析，将文本、音频、视频特征拼接后输入到LSTM网络。

**中期融合（Intermediate Fusion）**通过模态间交互模块实现融合。典型方法包括张量融合网络（TFN）[6]和低秩多模态融合（LMF）[7]。TFN通过张量外积建模模态间的三向交互，但参数量随特征维度呈三次方增长。LMF采用低秩近似方法降低计算复杂度，使其能够处理高维特征。这些方法能够捕捉模态间的非线性交互关系，但计算开销较大。

**晚期融合（Late Fusion）**，又称决策级融合，分别训练各模态的分类器，然后在决策层面融合预测结果。常见融合方式包括投票、加权平均和stacking。晚期融合的优点是灵活性强，各模态可以独立优化；缺点是忽略了模态间的低级交互信息。

近期，基于Transformer的多模态方法在多个数据集上取得了先进成果。例如，MISA[8]通过模态不变和模态特定的表示分离机制实现融合；Mulan[9]使用多任务学习框架同时处理多个情感分析任务。这些方法虽然性能优异，但需要大量训练数据和计算资源。

### 1.2.2 注意力机制在情感分析中的应用

注意力机制（Attention Mechanism）最初由Vaswani等人[10]在Transformer模型中提出，现已成为深度学习的基础组件。其核心思想是动态计算输入序列中不同元素的重要性权重，使模型能够聚焦于关键信息。

在多模态情感分析中，注意力机制可以发挥多种作用：

**跨模态注意力（Cross-modal Attention）**：计算不同模态之间的相互依赖关系。例如，在分析一个讽刺视频时，视觉模态的"微笑"表情可能与文本模态的"糟糕"形成对比，跨模态注意力能够捕捉这种矛盾信息，正确识别讽刺情感。

**自注意力（Self-Attention）**：在单个模态内部计算不同时刻特征的相关性。例如，在文本中，某些形容词（如"非常"、"极其"）会增强后续词语的情感强度，自注意力能够捕捉这种长距离依赖。

**层次化注意力**：在不同层次上应用注意力机制。例如，先在词级别计算注意力得到句子表示，再在句子级别计算注意力得到文档表示。这种层次化结构在处理长序列时特别有效。

Chen等人[11]提出使用多头注意力进行多模态融合，在CMU-MOSEI数据集上取得了当时最优的性能。他们的方法将三种模态作为序列输入到Transformer，通过自注意力层学习模态间和模态内的交互关系。

### 1.2.3 类别不平衡处理方法

针对类别不平衡问题，现有方法主要分为三类：数据层面、算法层面和后处理层面。

**数据层面的方法**通过重采样平衡数据集分布。过采样（Oversampling）复制少数类样本或合成新样本（如SMOTE[12]）；欠采样（Undersampling）随机删除多数类样本。这些方法简单直接，但过采样可能导致过拟合，欠采样可能丢失重要信息。

**算法层面的方法**通过修改损失函数或训练算法来平衡学习过程。Focal Loss[13]是代表性的方法，它在标准交叉熵的基础上引入调制因子 $(1-p_t)^\gamma$，降低简单样本的损失权重，使模型更关注困难样本。类别加权交叉熵（Class-weighted Cross Entropy）为不同类别分配不同权重，通常与类别频率成反比。此外，还有代价敏感学习（Cost-sensitive Learning）[14]和在线难样本挖掘（Online Hard Example Mining）[15]等方法。

**后处理层面的方法**通过调整决策阈值来平衡精确率和召回率。标准分类器使用argmax决策，相当于所有类别使用0.5的阈值（对于二分类）。对于不平衡数据，可以降低少数类的阈值，增加被预测为该类的样本数量。这种方法的优点是不需要重新训练模型，实现成本低；缺点是可能增加误报率。

然而，现有方法往往独立使用，缺乏系统性方案。本研究尝试组合多种策略，探索类别不平衡问题的系统性解决思路。

---

## 1.3 本文主要工作与贡献

本研究在CMU-MOSEI数据集的SDK标准子集上设计并实现了一个多模态情感分析系统，主要工作和贡献如下：

**（1）SDK子集数据特性分析与验证**

本文对CMU-MOSEI数据集的SDK标准子集进行了系统的特性分析。研究发现：

首先，SDK子集规模约为完整数据集的10%，如**图6**所示。SDK子集包含2,249个训练样本，而完整数据集包含22,834个训练样本，比例约为1:10。验证集和测试集的比例也约为1:10。这一规模差异对模型选择有重要影响。

其次，标签分布存在显著差异。SDK子集中性情感占50.4%，而完整数据集的报告值为26.1%，差异达24.3个百分点。这种分布差异意味着在SDK子集上训练的模型可能偏向预测中性情感，需要采取针对性措施。

最后，本研究发现预训练模型在小规模不平衡数据上表现不如简单特征。对比实验显示，GloVe词向量基线模型达到53.11%的测试准确率，而BERT混合模型仅为50.44%，下降了2.67个百分点。这一反直觉发现揭示了数据特性对模型选择的影响：在大规模数据上表现优异的预训练模型，在小规模不平衡数据上可能不如简单特征。

**（2）注意力融合机制设计与实现**

本文设计了多头跨模态注意力融合机制，通过自注意力层学习三种模态间的动态交互关系。该机制的主要创新包括：

首先，统一的模态投影层。将三种模态特征（300维GloVe、74维COVAREP、710维OpenFace）通过各自的编码器投影到统一的64维空间，解决了模态异构性问题。

其次，多头注意力设计。使用4个注意力头并行计算模态间的相互依赖关系，每个头可以学习不同类型的交互模式。例如，某个头可能学习"视觉表情如何增强文本情感"，另一个头可能学习"音频语调如何修正文本语义"。

最后，层归一化与聚合。通过LayerNorm稳定训练过程，通过平均聚合得到最终融合表示。实验表明，注意力融合相比简单特征拼接提升了1.63%的准确率（59.17% vs 57.54%），验证了动态模态交互的有效性。

**（3）类别不平衡系统性解决方案**

针对SDK子集严重的类别不平衡问题（Negative占10%，Neutral占50.4%），本文提出了系统的优化方案：

首先，通过类别权重策略解决Negative类完全失效问题。在使用标准交叉熵训练时，Negative类F1为0%，模型完全不预测该类。引入平方根权重后，Negative类F1恢复到25.97%，证明权重策略的有效性。然而，准确率从59.17%下降到56.80%，揭示了准确率与类别平衡之间的权衡关系。

其次，通过阈值优化实现轻量级性能提升。网格搜索发现，将Negative类的决策阈值从0.5降低到0.21时，Macro F1从0.4133提升到0.4340（+5.0%），而准确率仅损失0.44%。这一方法无需重新训练模型，适用于快速部署场景。

最后，通过重新训练结合数据平衡策略实现显著提升。使用标准交叉熵重新训练30个epoch，在第10个epoch选择验证集Macro F1最高的模型作为最终模型。该方案将Macro F1从0.4133提升到0.5011（+21.3%），Negative类F1从0.00%提升到27.59%，同时保持整体准确率为58.88%。这一系列实验提供了类别不平衡问题的系统性解决思路。

**（4）Web演示系统实现**

为验证方法的实用性，本文基于Streamlit框架实现了完整的Web演示系统。系统包括数据输入、特征提取、模型推理和结果展示等模块，用户可以通过简单的Web界面输入文本，查看情感分析结果和置信度分数。系统还生成概率分布柱状图，直观展示三类别的预测概率。系统的成功实现验证了本文方法的工程可行性，为实际应用部署奠定了基础。

---

## 1.4 论文组织结构

本文其余部分组织如下：

**第二章**介绍多模态情感分析的相关技术，包括多模态学习的定义与挑战、CMU-MOSEI数据集介绍、情感分析任务定义、深度学习基础技术（注意力机制、多模态融合策略、集成学习方法）以及类别不平衡处理方法（损失函数改进、类别权重策略、阈值优化技术）。

**第三章**详细描述系统设计，包括系统功能需求分析、总体架构设计、模块划分、数据流设计（输入模块、特征提取模块、融合推理模块、输出展示模块）以及界面设计（主界面布局、交互流程、可视化设计）。

**第四章**阐述关键技术实现，包括多模态特征提取（GloVe、COVAREP、OpenFace）、注意力融合机制（问题背景、跨模态注意力设计、实现细节）、类别权重策略（问题分析、权重计算、加权损失函数实现）以及系统性优化方案（阈值调整、损失函数对比、最终方案设计与实现、实验结果与分析）。

**第五章**展示系统实现与测试结果，包括开发环境与工具（硬件软件环境、开发框架与库）、系统界面展示（主界面截图、功能展示截图）、功能测试（单模态测试、多模态测试）以及性能测试（评估指标体系、混淆矩阵分析、各类别性能对比、与基线模型对比）。

**第六章**总结全文工作，包括系统设计与实现总结、关键技术创新总结、主要创新点（SDK子集数据特性发现与验证、注意力融合与类别权重结合方案、系统性类别不平衡解决方案）以及当前局限性和未来改进方向。

**参考文献**列出本文引用的所有文献。

**附录**包括核心代码、完整实验数据和部署指南。

---

**[第一章完成]**

**字数统计**: 约4,500字

**图表引用**: 需要在后续添加数据集分布图、模型架构图等

**文献引用**: 需要在后续完善参考文献列表
