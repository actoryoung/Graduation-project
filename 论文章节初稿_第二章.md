# 第二章 相关技术

## 2.1 多模态情感分析

### 2.1.1 多模态学习的定义与挑战

多模态学习（Multimodal Learning）是机器学习的一个重要分支，旨在整合来自多种模态（Modality）的信息以完成特定任务。模态是指数据的类型或表现形式，常见的模态包括文本（Text）、图像（Image）、音频（Audio）、视频（Video）等。在情感分析领域，文本传达语义内容，音频携带语气、语调和情感韵律信息，视觉包含面部表情、肢体语言和手势动作。

与单模态学习相比，多模态学习面临独特的挑战，这些挑战构成了本研究的核心技术难点：

**（1）模态异构性（Modality Heterogeneity）**

不同模态具有不同的表示空间和统计特性。文本是离散的符号序列，通过词表索引表示；音频是连续的一维时序信号，通常通过声学特征（如MFCC）表示；视频是高维的图像序列，包含空间和时间两个维度的信息。这种异构性使得直接比较或融合不同模态变得困难。例如，文本的"开心"和音频的"笑声"如何在一个统一的语义空间中表示？

解决模态异构性的常见方法是将各模态投影到统一的特征空间。本研究使用多层感知机（MLP）将300维文本特征、74维音频特征和710维视频特征分别编码为64维统一表示，为后续融合奠定基础。

**（2）模态对齐（Modal Alignment）**

在多模态数据中，不同模态的元素之间需要建立时序或语义对应关系。在视频情感分析中，文本的第3个词、音频的第1.5秒片段和视频的第45帧可能描述的是同一个语义单元。如果这些元素没有正确对齐，融合模型可能将不相关的信息强行结合，导致性能下降。

模态对齐的挑战在于：1）不同模态的采样率不同（文本是词级别，音频是帧级别，视频是帧或片段级别）；2）语义对齐不一定严格对应时序对齐；3）标注对齐信息成本高昂。本研究使用CMU-MOSEI数据集，该数据集已经提供了字级对齐信息，降低了模态对齐的难度。

**（3）模态互补性与冗余性（Complementarity and Redundancy）**

不同模态可能提供互补信息，也可能存在冗余信息。互补性指不同模态包含互不重叠的信息，例如视觉表情可能揭示文本中隐含的讽刺意味。冗余性指不同模态包含重复信息，例如文本说"我很开心"同时音频也是欢快的语调。

理想的多模态融合方法应该充分利用互补性，同时避免冗余信息的过度影响。如果两个模态高度冗余，简单拼接可能导致信息重复；如果两个模态互补但权重相同，可能导致重要模态被忽视。本研究使用的注意力机制能够动态学习不同模态的重要性，自动平衡互补性与冗余性。

**（4）模态缺失（Modal Missing）**

在实际应用中，某些模态可能不可用。例如，用户可能只上传图片而没有文字说明，或者视频质量较差导致音频信息无法提取。多模态系统需要具备处理模态缺失的能力，例如使用单模态训练的辅助模型，或者利用模态间的相关性推测缺失模态的内容。

本研究在系统设计中考虑了模态缺失问题，支持单独使用文本模态进行推理，对于音频和视频模态，如果预提取特征不可用，系统会给出提示而非直接报错。

### 2.1.2 CMU-MOSEI数据集介绍

CMU-MOSEI（Multimodal Opinion Sentiment and Emotion Intensity）[4]是当前多模态情感分析领域规模最大、使用最广泛的数据集之一，由卡内基梅隆大学发布。

**数据集规模**

完整CMU-MOSEI数据集包含23,453个视频片段，来自3,229个不同的说话人和965个不同的话题。每个视频片段的长度为4到12秒，确保包含足够的情感表达信息。数据集提供了标准的训练/验证/测试划分，分别为22,834/2,787/6,870个样本，并确保测试集说话人不与训练集重叠，避免了数据泄露问题。

**标签体系**

CMU-MOSEI提供两种类型的标签：情感强度（Sentiment Intensity）和情感类别（Sentiment Category）。情感强度是连续值，范围从-3（强负）到+3（强正），共7个级别：强负(-3)、负(-2)、弱负(-1)、中性(0)、弱正(+1)、正(+2)、强正(+3)。情感类别将7个强度离散化，通常简化为三类：Negative（-3,-2,-1）、Neutral（0）、Positive（+1,+2,+3）。

**多模态特征**

CMU-MOSEI提供了预提取的多模态特征，研究者可以直接使用而无需自行提取。这些特征包括：

1. **文本特征**：使用词向量（Word2Vec或GloVe）对文本进行编码。SDK提供了300维GloVe特征，每个词对应一个300维向量，句子通过平均池化得到固定长度表示。

2. **音频特征**：使用COVAREP（Coherent and Extracted Representation of Audio）工具提取74维声学特征。这些特征包括：
   - 音高（F0）相关特征：基频、基频包络等
   - 谐波噪声比（HNR）：衡量语音的周期性
   - 峰度（Kurtosis）：描述信号分布的形状
   - 语音概率（Voicing Probability）：判断每一帧是否为语音
   - MFCC系数：12维梅尔频率倒谱系数，描述频谱包络
   - 共振峰（Formants）：前三个共振峰频率F1、F2、F3

3. **视频特征**：使用OpenFace工具提取710维面部特征。这些特征包括：
   - 17个动作单元（Action Units）的强度，描述面部肌肉运动
   - 头部姿态（6维）：pitch、yaw、roll及其位置
   - 68个面部landmarks的二维坐标（136维）
   - Gaze方向（6维）：视线方向向量
   - 特征点置信度（2维）：landmark检测的可信度

**SDK子集特性**

本研究使用CMU-MOSEI的SDK（Software Development Kit）标准子集。SDK子集是一个预定义的子集，便于快速原型开发和算法验证。本研究发现SDK子集具有以下特性：

1. **规模差异**：SDK子集约为完整数据集的10%，如**图6**所示。训练集2,249样本（vs 22,834），验证集300样本（vs 2,787），测试集678样本（vs 6,870）。这种规模差异影响模型选择：在小规模数据上，复杂模型容易过拟合。

2. **标签分布差异**：SDK子集的标签分布与完整数据集报告值存在显著差异。SDK子集中性情感占50.4%，而完整数据集的报告值为26.1%；Negative情感SDK占10.0%，完整数据集报告30.2%。这种差异说明SDK子集不能简单代表完整数据集，实验结论需要谨慎推广。

3. **预训练模型局限性**：本研究发现，在SDK子集上，GloVe词向量（53.11%）优于BERT混合特征（50.44%）。这一反直觉发现揭示了预训练模型在小规模不平衡数据上的局限性，为数据集特性对模型选择的影响提供了实证证据。

### 2.1.3 情感分析任务定义

多模态情感分析任务可以形式化为分类问题或回归问题，具体取决于应用场景和标签类型。

**分类任务**

给定一个多模态样本 $x = \{T, A, V\}$，其中 $T$ 是文本序列，$A$ 是音频特征，$V$ 是视频特征，目标是预测情感类别标签 $y \in Y$。对于3类分类任务，$Y = \{\text{Negative}, \text{Neutral}, \text{Positive}\}$。

分类任务的输出是离散标签，可以使用准确率（Accuracy）、精确率（Precision）、召回率（Recall）和F1分数（F1-Score）等指标评估。

$$ \text{Accuracy} = \frac{\text{正确分类数}}{\text{总样本数}} $$

$$ \text{Precision}_c = \frac{TP_c}{TP_c + FP_c} $$

$$ \text{Recall}_c = \frac{TP_c}{TP_c + FN_c} $$

$$ \text{F1}_c = 2 \cdot \frac{\text{Precision}_c \cdot \text{Recall}_c}{\text{Precision}_c + \text{Recall}_c} $$

其中，$c$ 表示某个类别，$TP$、$FP$、$FN$ 分别表示真正例、假正例和假反例。

**回归任务**

给定多模态样本 $x$，目标是预测情感强度值 $y \in [-3, +3]$。回归任务可以使用均方误差（MSE）、平均绝对误差（MAE）或皮尔逊相关系数评估。

$$ \text{MSE} = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2 $$

$$ \text{MAE} = \frac{1}{N} \sum_{i=1}^{N} |y_i - \hat{y}_i| $$

$$ \text{Correlation} = \frac{\sum_{i=1}^{N}(y_i - \bar{y})(\hat{y}_i - \bar{\hat{y}})}{\sqrt{\sum_{i=1}^{N}(y_i - \bar{y})^2 \sum_{i=1}^{N}(\hat{y}_i - \bar{\hat{y}})^2}} $$

**本研究任务设置**

本研究采用3类分类任务，将7类情感强度简化为3类：Negative（-3,-2,-1）、Neutral（0）、Positive（+1,+2,+3）。这种简化的理由是：1）3类任务更符合实际应用需求（积极/中性/消极）；2）简化后的类别分布仍然存在不平衡（10% vs 50% vs 40%），保留了类别不平衡问题的核心挑战；3）实验证明3类任务的准确率比7类提升4.43%（57.54% vs 53.11%），说明简化是合理的。

---

## 2.2 深度学习基础技术

### 2.2.1 注意力机制（Attention Mechanism）

注意力机制最初由Vaswani等人[10]在2017年提出，用于机器翻译任务，现已成为深度学习的基础组件。其核心思想是动态计算输入序列中不同元素的重要性权重，使模型能够聚焦于关键信息。

**缩放点积注意力（Scaled Dot-Product Attention）**

给定查询（Query）$Q$、键（Key）$K$和值（Value）$V$，注意力机制计算如下：

$$ \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V $$

其中，$QK^T$ 计算查询和键的相似度，$\sqrt{d_k}$ 是缩放因子（$d_k$ 是键的维度），softmax归一化为概率分布，最后加权求和得到输出。

**多头注意力（Multi-Head Attention）**

多头注意力使用多组查询、键、值并行计算，每组称为一个"头"（Head）。不同头可以学习不同类型的注意力模式。

$$ \text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, ..., \text{head}_h)W^O $$

$$ \text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V) $$

其中，$h$ 是头的数量，$W_i^Q, W_i^K, W_i^V$ 是第 $i$ 个头的投影矩阵，$W^O$ 是输出投影矩阵。

**在多模态情感分析中的应用**

注意力机制在多模态情感分析中可以发挥多种作用：

1. **跨模态注意力**：计算不同模态之间的相互依赖关系。例如，在分析一个讽刺评论时，视觉模态的"微笑"可能与文本模态的"糟糕"形成对比，跨模态注意力能够捕捉这种矛盾信息。本研究设计的跨模态注意力将三种模态作为序列输入，每个模态作为序列中的一个元素，通过自注意力学习模态间的交互权重。

2. **时序注意力**：在单个模态内部，不同时刻的特征重要性不同。例如，文本中的"非常"、"极其"等程度副词会增强后续词语的情感强度，时序注意力能够捕捉这种长距离依赖。音频中的重音部分、视频中的关键表情帧也应该获得更高的注意力权重。

3. **层次化注意力**：在不同层次上应用注意力机制。例如，先在词级别计算注意力得到句子表示，再在句子级别计算注意力得到文档表示。这种层次化结构在处理长序列时特别有效，能够构建从局部到全局的层次化表示。

本研究使用4个头的多头注意力，每个头的维度为16（总维度64）。不同头可以学习不同类型的模态交互，例如某个头可能关注"视觉如何增强文本"，另一个头可能关注"音频如何修正文本"。

### 2.2.2 多模态融合策略

多模态融合是多模态学习的核心问题，指如何整合来自不同模态的信息。根据融合时机的不同，可分为早期融合、中期融合和晚期融合三类。

**早期融合（Early Fusion）**

早期融合又称特征级融合（Feature-level Fusion），是最直接的融合方式。该方法在特征层面直接拼接多模态特征，形成统一的高维特征向量，然后输入到分类器。

$$ h = \text{Concat}(h_T, h_A, h_V) $$

$$ y = \text{Classifier}(h) $$

其中，$h_T, h_A, h_V$ 分别是文本、音频、视频的特征表示，$\text{Concat}$ 是拼接操作，$\text{Classifier}$ 是分类器（如多层感知机）。

早期融合的优点是实现简单、计算高效，所有模态共享后续的决策过程。缺点是：1）无法学习模态间的动态关系，所有时刻使用相同的融合方式；2）对模态质量差异敏感，某个模态的噪声可能严重影响结果；3）特征维度叠加导致参数量增加。

本研究基线模型采用早期融合，将300维GloVe、74维COVAREP和710维OpenFace特征拼接为1084维向量，经过多层感知机分类。该基线达到57.54%的准确率，为后续改进提供了起点。

**中期融合（Intermediate Fusion）**

中期融合通过模态间交互模块实现融合，能够在特征融合的同时学习模态间的动态关系。代表性方法包括张量融合网络（TFN）和低秩多模态融合（LMF）。

张量融合网络（TFN）[6]通过张量外积建模模态间的三向交互：

$$ h = \text{Fuse}(h_T, h_A, h_V) = h_T \otimes h_A \otimes h_V $$

其中，$\otimes$ 是张量外积。然而，三向张量的参数量随特征维度呈三次方增长，计算开销巨大。

低秩多模态融合（LMF）[7]采用低秩近似方法降低计算复杂度：

$$ h = \sum_{l=1}^{L} (\text{Rank-1 Tensor}_l \odot h_T \odot h_A \odot h_V) $$

其中，$L$ 是低秩因子的数量，$\odot$ 是Hadamard积。LMF将参数复杂度从 $O(d^3)$ 降低到 $O(Ld)$，使其能够处理高维特征。

中期融合的优点是能够捕捉模态间的非线性交互关系。缺点是计算开销较大，需要设计合适的交互机制。本研究使用的跨模态注意力属于中期融合的一种，通过自注意力层学习模态间的动态权重，相比TFN和LMF更轻量高效。

**晚期融合（Late Fusion）**

晚期融合又称决策级融合（Decision-level Fusion），分别训练各模态的分类器，然后在决策层面融合预测结果。

$$ p_T = \text{Classifier}_T(h_T), \quad p_A = \text{Classifier}_A(h_A), \quad p_V = \text{Classifier}_V(h_V) $$

$$ p = \text{Fuse}(p_T, p_A, p_V) $$

$$ y = \arg\max(p) $$

常见融合方式包括：
- **多数投票**：预测最多的类别作为最终结果
- **加权平均**：为各模态分配权重，加权平均概率分布
- **Stacking**：训练一个元分类器，输入各模态的预测结果，输出最终预测

晚期融合的优点是灵活性强，各模态可以独立优化，一个模态的改进不会影响其他模态。缺点是忽略了模态间的低级交互信息，可能无法充分利用模态间的互补性。

本研究在最终阶段采用晚期融合策略，组合两个基模型（S3+S4和S3）的预测结果，通过加权投票得到最终预测。这种集成方式达到了59.47%的准确率，优于任一单模型。

### 2.2.3 集成学习方法

集成学习（Ensemble Learning）通过组合多个基学习器（Base Learner）来提升泛化性能。其核心思想是"三个臭皮匠顶个诸葛亮"：虽然单个模型可能存在偏差或方差，但多个模型的组合往往能取得更好的性能。

**Bagging与Boosting**

Bagging（Bootstrap Aggregating）通过自助采样（Bootstrap Sampling）训练多个模型，每个模型使用不同的训练子集，最后通过平均或投票得到最终预测。随机森林是Bagging的代表性方法。

Boosting通过迭代训练一系列弱学习器，每个后续学习器关注前面学习器预测错误的样本。AdaBoost和Gradient Boosting是Boosting的代表性方法。XGBoost、LightGBM等是Gradient Boosting的高效实现。

**软投票与硬投票**

在分类任务中，集成预测可以采用硬投票或软投票：

- **硬投票**：每个基模型预测一个类别，最终结果为多数类别。
  $$ y = \text{mode}(y_1, y_2, ..., y_M) $$

- **软投票**：每个基模型输出类别概率，最终结果为加权平均概率的argmax。
  $$ p = \sum_{i=1}^{M} w_i \cdot p_i $$
  $$ y = \arg\max(p) $$

其中，$M$ 是基模型数量，$w_i$ 是第 $i$ 个模型的权重，$\sum w_i = 1$。软投票通常优于硬投票，因为它利用了概率信息，能够表达预测的置信度。

**加权投票策略**

加权投票的关键是如何设置各模型的权重。常见策略包括：

1. **等权重**：所有模型权重相同，$w_i = 1/M$。适用于模型性能相近的情况。

2. **基于性能**：根据验证集性能分配权重，性能好的模型权重更大。例如：
   $$ w_i = \frac{\text{Acc}_i}{\sum_j \text{Acc}_j} $$

3. **网格搜索**：在验证集上搜索最优权重组合。例如，对于两个模型，可以搜索 $w_1 \in [0.1, 0.2, ..., 1.0]$，$w_2 = 1 - w_1$，选择验证集Macro F1最高的权重。

4. **学习权重**：将权重作为可学习参数，通过优化算法（如梯度下降）学习最优权重。

本研究采用加权软投票策略集成两个基模型：模型1是S3+S4（使用类别权重），模型2是S3（不使用权重）。通过网格搜索发现最优权重为[1.5, 1.0]，集成后准确率为59.47%，Macro F1为0.5070。相比单模型，集成在保持高准确率的同时改善了类别平衡。

---

## 2.3 类别不平衡处理

### 2.3.1 损失函数改进方法

针对类别不平衡问题，研究者提出了多种改进的损失函数，旨在通过优化目标函数的设计来平衡模型对不同类别的关注程度。

**Focal Loss**

Focal Loss[13]是Lin等人针对目标检测中的类别不平衡问题提出的，其核心思想是降低简单样本的损失权重，使模型更关注困难样本。Focal Loss在标准交叉熵的基础上引入调制因子：

$$ \text{FL}(p_t) = -\alpha_t (1 - p_t)^\gamma \log(p_t) $$

其中，$p_t$ 是模型对正确类别的预测概率，$\alpha_t$ 是类别权重，$\gamma$ 是聚焦参数。

调制因子 $(1 - p_t)^\gamma$ 的作用是：当 $p_t$ 接近1（样本被正确分类且置信度高）时，$(1 - p_t)^\gamma$ 接近0，损失被降低；当 $p_t$ 接近0（样本被错误分类或置信度低）时，$(1 - p_t)^\gamma$ 接近1，损失保持不变。因此，Focal Loss自动降低了简单样本的权重，使模型更关注困难样本。

参数 $\gamma$ 控制聚焦程度。$\gamma = 0$ 时，Focal Loss退化为标准交叉熵；$\gamma$ 越大，对简单样本的抑制越强。原文推荐 $\gamma = 2$。

然而，Focal Loss在情感分析等任务上的效果并不总是优于标准交叉熵。本研究实验表明，在SDK子集上，Focal Loss的Macro F1为0.4873，低于标准交叉熵的0.5011。可能的原因是：1）Focal Loss增加了优化难度，在小规模数据上容易过拟合；2）情感分析任务的"困难样本"定义不如目标检测清晰；3）调制因子可能过度抑制了多数类的有用样本。

**类别加权交叉熵**

类别加权交叉熵（Class-weighted Cross Entropy）为不同类别分配不同权重，通常与类别频率成反比：

$$ \text{Loss} = -\frac{1}{N} \sum_{i=1}^{N} w_{y_i} \log(p_{y_i}) $$

其中，$w_c$ 是第 $c$ 类的权重，$y_i$ 是样本 $i$ 的真实标签，$p_{y_i}$ 是预测概率。

常见权重计算方式包括：

1. **线性权重**：$w_c = N / (C \times n_c)$，其中 $N$ 是总样本数，$C$ 是类别数，$n_c$ 是第 $c$ 类的样本数。

2. **平方根权重**：$w_c = \sqrt{N / n_c}$，降低权重的差异幅度，避免过度补偿。

以SDK子集训练集为例（Negative: 224, Neutral: 1134, Positive: 891），线性权重为[2.07, 0.41, 0.52]，平方根权重为[1.54, 0.69, 0.77]。实验表明，平方根权重能够在恢复Negative类识别能力（F1=25.97%）的同时保持较好的整体准确率（56.80%），而线性权重虽然提升了Negative F1，但整体准确率下降更多。

**Macro F1 Loss**

Macro F1 Loss直接优化Macro F1分数，试图解决优化目标与评估指标不一致的问题。标准交叉熵优化的是准确率，而我们关心的是Macro F1，这导致模型可能向错误方向优化。

然而，Macro F1是一个不可微的指标（包含argmax操作），无法直接优化。需要使用可微分近似，例如：

1. **软近似**：用softmax替代argmax，用连续的F1近似离散F1。
2. **松弛近似**：使用sigmoid函数放松0-1硬分类。

本研究实现了Macro F1 Loss的可微分近似，但实验效果不佳（Macro F1=0.4730），低于标准交叉熵。可能的原因是：1）近似不够准确，导致优化方向错误；2）Macro F1 Loss的梯度信号不稳定，训练难以收敛；3）在大规模训练下，标准交叉熵的梯度更加可靠。

### 2.3.2 类别权重策略

类别权重策略是一种简单有效的类别不平衡处理方法，通过在损失函数中为不同类别分配不同权重来平衡训练过程。

**权重计算方法**

常见权重计算方式包括：

1. **倒数频率权重**：
   $$ w_c = \frac{1}{f_c} = \frac{N}{n_c} $$
   其中，$f_c = n_c / N$ 是第 $c$ 类的频率。少数类频率低，权重高；多数类频率高，权重低。

2. **平方根倒数权重**：
   $$ w_c = \frac{1}{\sqrt{f_c}} = \sqrt{\frac{N}{n_c}} $$
   平方根降低了权重的差异幅度，避免过度补偿。

3. **对数权重**：
   $$ w_c = \log\left(\frac{N}{n_c}\right) + 1 $$
   对数进一步压缩权重差异，适用于极端不平衡场景。

4. **有效类别权重**：
   $$ w_c = \frac{1}{\beta(n_c / N) + (1 - \beta)} $$
   其中，$\beta \in [0, 1]$ 是超参数，控制权重平滑程度。

**权重归一化**

权重通常需要归一化，避免整体损失量级变化：

$$ w_c' = \frac{w_c}{\sum_{j=1}^{C} w_j / C} $$

这样，权重的平均值为1，整体损失量级与无权重时相近。

**超参数搜索**

类别权重的设置是超参数，需要在验证集上搜索。常见搜索策略包括：

1. **网格搜索**：尝试不同的权重计算方式（线性、平方根、对数），选择验证集Macro F1最高的设置。

2. **贝叶斯优化**：将权重视为连续参数，使用贝叶斯优化搜索最优值。

3. **启发式搜索**：根据类别比例手动调整权重，观察模型行为。

本研究对比了无权重、平方根权重和线性权重三种设置，通过验证集Macro F1确定最优方案。实验发现，平方根权重达到了最佳的平衡（Negative F1=25.97%, Acc=56.80%），而线性权重虽然提升了Negative F1，但整体准确率下降更多（约2%）。

### 2.3.3 阈值优化技术

阈值优化是一种轻量级的后处理方法，不需要重新训练模型，通过调整决策阈值来平衡精确率和召回率。

**标准决策阈值**

在分类任务中，模型输出各类别的概率分布 $p = [p_1, p_2, ..., p_C]$，标准决策使用argmax：

$$ \hat{y} = \arg\max_c p_c $$

这相当于所有类别使用相同的阈值（通常为0.5，如果存在类别偏置则为类别先验概率的倒数）。

**阈值调整原理**

对于不平衡数据，可以降低少数类的决策阈值，增加被预测为该类的样本数量，从而提升召回率。

给定阈值向量 $\tau = [\tau_1, \tau_2, ..., \tau_C]$，决策规则变为：

$$ \hat{y} = \arg\max_c \frac{p_c}{\tau_c} $$

等价地，如果 $p_c > \tau_c$，则认为样本可能属于第 $c$ 类。降低 $\tau_c$ 会使更多样本被预测为第 $c$ 类。

**网格搜索**

最优阈值可以通过网格搜索获得：

1. 定义搜索空间：例如，Negative类阈值 $\tau_{\text{neg}} \in [0.1, 0.5]$，步长0.01；其他类别阈值固定为0.5。

2. 在验证集上评估：对于每组阈值，计算验证集Macro F1。

3. 选择最优阈值：选择Macro F1最高的阈值配置。

本研究通过网格搜索发现，将Negative类阈值从0.5降低到0.21时，Macro F1从0.4133提升到0.4340（+5.0%），而准确率仅损失0.44%。这表明阈值优化是一种高效的轻量级方法，适用于快速部署场景。

**自适应阈值**

除了固定阈值，还可以设计自适应阈值策略：

1. **基于验证集**：使用验证集的类别分布自适应调整阈值。

2. **基于置信度**：根据模型预测的置信度动态调整阈值，置信度低时降低阈值，置信度高时提高阈值。

3. **在线调整**：在推理过程中根据累积的预测统计动态调整阈值。

---

**[第二章完成]**

**字数统计**: 约6,500字

**关键公式**: 15个

**技术细节**: 注意力机制、融合策略、集成学习、类别不平衡处理

**文献引用**: [4][6][7][10][13]等
